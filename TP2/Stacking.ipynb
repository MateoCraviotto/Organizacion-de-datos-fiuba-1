{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2: Análisis con Stacking - Organización de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Alumnos y Padrón**\n",
    "+ Craviotto Roitbarg, Mateo Exequiel - 106255 \n",
    "+ Gómez, Joaquín - 103735\n",
    "\n",
    "https://github.com/joaqogomez/Organizacion-de-datos-fiuba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuraciones Iniciales\n",
    "Primero, importamos las bibliotecas que vamos a utilizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import dividir_dataset\n",
    "from preprocessing import preparar_dataset\n",
    "from preprocessing import normalizar_datos\n",
    "from preprocessing import aplicar_one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones_auxiliares import graficar_auc_roc\n",
    "from funciones_auxiliares import traer_df\n",
    "from funciones_auxiliares import graficar_matriz_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga del set de datos\n",
    "Cargamos el dataset y aplicamos las funciones necesarias para adecuarlo al modelo. También segmentamos el dataset en X e y (target):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = traer_df()\n",
    "df = preparar_dataset(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También segmentamos el dataset en X e y (target), y luego lo dividimos en subsets de entrenamiento y validation development (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dividir_dataset(df)\n",
    "X = aplicar_one_hot_encoding(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignamos los clasificadores a ser utilizados para realizar el ensamble. En este caso, utilizamos los que mejor ROC-AUC score proporcionaron: KNN, SVM y Random Forest, cada uno con sus mejores hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = KNeighborsClassifier(n_neighbors = 55, weights = 'uniform', metric = 'correlation')\n",
    "clf_2 = SVC(kernel = 'poly', C = 10, degree = 3, probability = True)\n",
    "clf_3 = RandomForestClassifier(max_depth = 16, n_estimators = 500, criterion = 'entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y predicción con el dataset original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el ensamble con los modelos anteriormente mencionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = StackingClassifier(\n",
    "    estimators=[('clf_1', clf_1), ('clf_2', clf_2), ('clf_3', clf_3)], n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos los datos del dataset original y entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = X_train.copy()\n",
    "X_train, X_test = normalizar_datos(X_train, X_test)\n",
    "stacking.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos que este prediga sobre el subset de validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stacking.predict(X_test)\n",
    "y_pred_proba = stacking.predict_proba(X_test)[:,1]\n",
    "graficar_auc_roc(y_test,y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar un AUC score bastante alto, aproximadamente de 0.92. Tiene sentido, pues estamos realizando un ensamble de los modelos que mejores resultados dieron.\n",
    "\n",
    "Imprimimos el classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No Tiene Alto Valor Adquisitivo', 'Tiene Alto Valor Adquisitivo'], digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los valores de precision y recall para las instancias con pocos ingresos son muy elevados. Por otra parte, las instancias con alto valor adquisitivo son predichas con una precision relativamente alta, pero un recall regular. Se podría decir que al Stacking le cuesta más clasificar estas últimas. Esto se ve más claramente en la siguiente matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones_auxiliares import graficar_matriz_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_matriz_confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y predicción con el dataset ampliado\n",
    "Como otra técnica de preprocesamiento, decidimos expandir el dataset utilizando clustering para obtener cuatro nuevas columnas. Las columnas corresponden a la utilización de K-means con 2, 4, 6 y 10 como cantidad de clusters usados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import expandir_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expandimos el dataset y realizamos el split del mismo en los subsets de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exp = expandir_dataset(X)\n",
    "X_exp_train, X_exp_test, y_exp_train, y_exp_test = train_test_split(X_exp, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos el ensamble para el dataset expandido con los modelos anteriormente mencionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_expandido = StackingClassifier(\n",
    "    estimators=[('clf_1', clf_1), ('clf_2', clf_2), ('clf_3', clf_3)], n_jobs = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizamos los datos del dataset ampliado y entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exp_train_original = X_exp_train.copy()\n",
    "X_exp_train, X_exp_test = normalizar_datos(X_exp_train, X_exp_test)\n",
    "stacking_expandido.fit(X_exp_train, y_exp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hacemos que este prediga sobre el subset de validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = stacking_expandido.predict(X_exp_test)\n",
    "y_pred_proba = stacking_expandido.predict_proba(X_exp_test)[:,1]\n",
    "graficar_auc_roc(y_exp_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar un AUC score levemente superior al del Stacking con el dataset original. A continuación, vemos el classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['No Tiene Alto Valor Adquisitivo', 'Tiene Alto Valor Adquisitivo'], digits = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ve una muy leve mejora en el recall para las instancias que poseen alto valor adquisitivo. Es decir, estas instancias fueron mejor clasificadas según el target. Esto se ve en la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_matriz_confusion(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción con el dataset nuevo\n",
    "A continuación, realizamos la predicción con Stacking con el dataset expandido sobre el dataset de predicciones nuevo, y la escribimos al archivo 'Stacking.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funciones_auxiliares import traer_df_predicciones\n",
    "from preprocessing import preparar_df_predicciones\n",
    "from funciones_auxiliares import escribir_predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicciones = traer_df_predicciones()\n",
    "ids, df_predicciones = preparar_df_predicciones(df_predicciones)\n",
    "df_predicciones = aplicar_one_hot_encoding(df_predicciones)\n",
    "df_predicciones = expandir_dataset(df_predicciones)\n",
    "X_exp_train_normalizado, df_predicciones = normalizar_datos(X_exp_train_original, df_predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = stacking_expandido.predict(df_predicciones)\n",
    "escribir_predicciones(ids, predicciones, \"Stacking\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
